# app/llm_engine.py

def generate_answer(question: str, context: list):
    """
    Placeholder: Replace with a real LLM call.
    Returns an answer string based on context.
    """
    # TODO: Integrate with OpenAI, Hugging Face, or other LLM provider
    return f"Mock answer for '{question}' with context: {context}"
